{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306534, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>event</th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e2127556f4f64592b11af22de27a7932</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '2906b810c7d4411798c6938adc9daaa5'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ec6ce2a7e7949b1bf142def7d0e0586</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68617ca6246f4fbc85e91a2a49552598</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             person           event  \\\n",
       "0  78afa995795e4d85b5d9ceeca43f5fef  offer received   \n",
       "1  a03223e636434f42ac4c3df47e8bac43  offer received   \n",
       "2  e2127556f4f64592b11af22de27a7932  offer received   \n",
       "3  8ec6ce2a7e7949b1bf142def7d0e0586  offer received   \n",
       "4  68617ca6246f4fbc85e91a2a49552598  offer received   \n",
       "\n",
       "                                              value  time  \n",
       "0  {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}     0  \n",
       "1  {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}     0  \n",
       "2  {'offer id': '2906b810c7d4411798c6938adc9daaa5'}     0  \n",
       "3  {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}     0  \n",
       "4  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>306534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>366.382940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>200.326314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time\n",
       "count  306534.000000\n",
       "mean      366.382940\n",
       "std       200.326314\n",
       "min         0.000000\n",
       "25%       186.000000\n",
       "50%       408.000000\n",
       "75%       528.000000\n",
       "max       714.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.200000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.583915</td>\n",
       "      <td>5.831905</td>\n",
       "      <td>2.321398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reward  difficulty   duration\n",
       "count  10.000000   10.000000  10.000000\n",
       "mean    4.200000    7.700000   6.500000\n",
       "std     3.583915    5.831905   2.321398\n",
       "min     0.000000    0.000000   3.000000\n",
       "25%     2.000000    5.000000   5.000000\n",
       "50%     4.000000    8.500000   7.000000\n",
       "75%     5.000000   10.000000   7.000000\n",
       "max    10.000000   20.000000  10.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>1.700000e+04</td>\n",
       "      <td>14825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.531412</td>\n",
       "      <td>2.016703e+07</td>\n",
       "      <td>65404.991568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.738580</td>\n",
       "      <td>1.167750e+04</td>\n",
       "      <td>21598.299410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.013073e+07</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.016053e+07</td>\n",
       "      <td>49000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.017080e+07</td>\n",
       "      <td>64000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.017123e+07</td>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>2.018073e+07</td>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  became_member_on         income\n",
       "count  17000.000000      1.700000e+04   14825.000000\n",
       "mean      62.531412      2.016703e+07   65404.991568\n",
       "std       26.738580      1.167750e+04   21598.299410\n",
       "min       18.000000      2.013073e+07   30000.000000\n",
       "25%       45.000000      2.016053e+07   49000.000000\n",
       "50%       58.000000      2.017080e+07   64000.000000\n",
       "75%       73.000000      2.017123e+07   80000.000000\n",
       "max      118.000000      2.018073e+07  120000.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>event</th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e2127556f4f64592b11af22de27a7932</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '2906b810c7d4411798c6938adc9daaa5'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ec6ce2a7e7949b1bf142def7d0e0586</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68617ca6246f4fbc85e91a2a49552598</td>\n",
       "      <td>offer received</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             person           event  \\\n",
       "0  78afa995795e4d85b5d9ceeca43f5fef  offer received   \n",
       "1  a03223e636434f42ac4c3df47e8bac43  offer received   \n",
       "2  e2127556f4f64592b11af22de27a7932  offer received   \n",
       "3  8ec6ce2a7e7949b1bf142def7d0e0586  offer received   \n",
       "4  68617ca6246f4fbc85e91a2a49552598  offer received   \n",
       "\n",
       "                                              value  time  \n",
       "0  {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}     0  \n",
       "1  {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}     0  \n",
       "2  {'offer id': '2906b810c7d4411798c6938adc9daaa5'}     0  \n",
       "3  {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}     0  \n",
       "4  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transcript.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68be06ca386d4c31939f3a4f0e3dd783</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>20170212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610b486422d4921ae7d2bf64640c50b</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>20170715</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38fe809add3b4fcf9315a9694bb96ff5</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>20180712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78afa995795e4d85b5d9ceeca43f5fef</th>\n",
       "      <td>F</td>\n",
       "      <td>75</td>\n",
       "      <td>20170509</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a03223e636434f42ac4c3df47e8bac43</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>20170804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d5f3a774f3d4714ab0c092238f3a1d7</th>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>20180604</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2cb4f97358b841b9a9773a7aa05a9d77</th>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>20180713</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01d26f638c274aa0b965d24cefe3183f</th>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>73000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9dc1421481194dcd9400aec7c9ae6366</th>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>20160307</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4052622e5ba45a8b96b59aba68cf068</th>\n",
       "      <td>F</td>\n",
       "      <td>62</td>\n",
       "      <td>20170722</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 gender  age  became_member_on    income\n",
       "id                                                                      \n",
       "68be06ca386d4c31939f3a4f0e3dd783   None  118          20170212       NaN\n",
       "0610b486422d4921ae7d2bf64640c50b      F   55          20170715  112000.0\n",
       "38fe809add3b4fcf9315a9694bb96ff5   None  118          20180712       NaN\n",
       "78afa995795e4d85b5d9ceeca43f5fef      F   75          20170509  100000.0\n",
       "a03223e636434f42ac4c3df47e8bac43   None  118          20170804       NaN\n",
       "...                                 ...  ...               ...       ...\n",
       "6d5f3a774f3d4714ab0c092238f3a1d7      F   45          20180604   54000.0\n",
       "2cb4f97358b841b9a9773a7aa05a9d77      M   61          20180713   72000.0\n",
       "01d26f638c274aa0b965d24cefe3183f      M   49          20170126   73000.0\n",
       "9dc1421481194dcd9400aec7c9ae6366      F   83          20160307   50000.0\n",
       "e4052622e5ba45a8b96b59aba68cf068      F   62          20170722   82000.0\n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make profile id the index\n",
    "profile_id_as_index = profile.copy()\n",
    "profile_id_as_index.set_index('id', inplace=True)\n",
    "profile_id_as_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>event</th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "      <th>offer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>9fa9ae8f57894cc9a3b8a9bbe0fc1b2f</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': '2906b810c7d4411798c6938adc9daaa5...</td>\n",
       "      <td>0</td>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12672</th>\n",
       "      <td>fe97aa22dd3e48c8b143116a8403dd52</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...</td>\n",
       "      <td>0</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12679</th>\n",
       "      <td>629fc02d56414d91bca360decdfa9288</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': '9b98b8c7a33c4b65b9aebfe6a799e6d9...</td>\n",
       "      <td>0</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>676506bad68e4161b9bbaffeb039626b</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': 'ae264e3637204a6fb9bb56bc8210ddfd...</td>\n",
       "      <td>0</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12697</th>\n",
       "      <td>8f7dd3b2afe14c078eb4f6e6fe4ba97d</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': '4d5c57ea9a6940dd891ad53e9dbe8da0...</td>\n",
       "      <td>0</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306475</th>\n",
       "      <td>0c027f5f34dd4b9eba0a25785c611273</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': '2298d6c36e964ae4a3e7e9706d1fb8c2...</td>\n",
       "      <td>714</td>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306497</th>\n",
       "      <td>a6f84f4e976f44508c358cc9aba6d2b3</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': '2298d6c36e964ae4a3e7e9706d1fb8c2...</td>\n",
       "      <td>714</td>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306506</th>\n",
       "      <td>b895c57e8cd047a8872ce02aa54759d6</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...</td>\n",
       "      <td>714</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306509</th>\n",
       "      <td>8431c16f8e1d440880db371a68f82dd0</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...</td>\n",
       "      <td>714</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306527</th>\n",
       "      <td>24f56b5e1849462093931b164eb803b5</td>\n",
       "      <td>offer completed</td>\n",
       "      <td>{'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...</td>\n",
       "      <td>714</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33579 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  person            event  \\\n",
       "12658   9fa9ae8f57894cc9a3b8a9bbe0fc1b2f  offer completed   \n",
       "12672   fe97aa22dd3e48c8b143116a8403dd52  offer completed   \n",
       "12679   629fc02d56414d91bca360decdfa9288  offer completed   \n",
       "12692   676506bad68e4161b9bbaffeb039626b  offer completed   \n",
       "12697   8f7dd3b2afe14c078eb4f6e6fe4ba97d  offer completed   \n",
       "...                                  ...              ...   \n",
       "306475  0c027f5f34dd4b9eba0a25785c611273  offer completed   \n",
       "306497  a6f84f4e976f44508c358cc9aba6d2b3  offer completed   \n",
       "306506  b895c57e8cd047a8872ce02aa54759d6  offer completed   \n",
       "306509  8431c16f8e1d440880db371a68f82dd0  offer completed   \n",
       "306527  24f56b5e1849462093931b164eb803b5  offer completed   \n",
       "\n",
       "                                                    value  time  \\\n",
       "12658   {'offer_id': '2906b810c7d4411798c6938adc9daaa5...     0   \n",
       "12672   {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...     0   \n",
       "12679   {'offer_id': '9b98b8c7a33c4b65b9aebfe6a799e6d9...     0   \n",
       "12692   {'offer_id': 'ae264e3637204a6fb9bb56bc8210ddfd...     0   \n",
       "12697   {'offer_id': '4d5c57ea9a6940dd891ad53e9dbe8da0...     0   \n",
       "...                                                   ...   ...   \n",
       "306475  {'offer_id': '2298d6c36e964ae4a3e7e9706d1fb8c2...   714   \n",
       "306497  {'offer_id': '2298d6c36e964ae4a3e7e9706d1fb8c2...   714   \n",
       "306506  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...   714   \n",
       "306509  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...   714   \n",
       "306527  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...   714   \n",
       "\n",
       "                                offer_id  \n",
       "12658   2906b810c7d4411798c6938adc9daaa5  \n",
       "12672   fafdcd668e3743c1bb461111dcafc2a4  \n",
       "12679   9b98b8c7a33c4b65b9aebfe6a799e6d9  \n",
       "12692   ae264e3637204a6fb9bb56bc8210ddfd  \n",
       "12697   4d5c57ea9a6940dd891ad53e9dbe8da0  \n",
       "...                                  ...  \n",
       "306475  2298d6c36e964ae4a3e7e9706d1fb8c2  \n",
       "306497  2298d6c36e964ae4a3e7e9706d1fb8c2  \n",
       "306506  fafdcd668e3743c1bb461111dcafc2a4  \n",
       "306509  fafdcd668e3743c1bb461111dcafc2a4  \n",
       "306527  fafdcd668e3743c1bb461111dcafc2a4  \n",
       "\n",
       "[33579 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out the customer who have completed the offers.\n",
    "completed_offers = df[df['event'] == 'offer completed'].copy()\n",
    "completed_offers['offer_id'] = completed_offers.apply(lambda row: row.value['offer_id'], axis=1)\n",
    "completed_offers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>event</th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>389bc3fa690240e798340f5a15918d5c</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>d1ede868e29245ea91818a903fec04c6</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>102e9454054946fda62242d2e176fdce</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>02c083884c7d45b39cc68e1314fec56c</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>be8a5d1981a2458d90b255ddc7e0d174</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>7f370edef8ae471bb1e3067f84f5a9d0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>a9c89c0882154db68a99adcf81eac27e</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>798d915dfb6a4477adf06802ba29477e</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>e4c38c75c12f4bec9fb35546b14c5fd5</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>31bf20236dda4f92b15153c439352a25</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 person         event  \\\n",
       "12650  389bc3fa690240e798340f5a15918d5c  offer viewed   \n",
       "12651  d1ede868e29245ea91818a903fec04c6  offer viewed   \n",
       "12652  102e9454054946fda62242d2e176fdce  offer viewed   \n",
       "12653  02c083884c7d45b39cc68e1314fec56c  offer viewed   \n",
       "12655  be8a5d1981a2458d90b255ddc7e0d174  offer viewed   \n",
       "...                                 ...           ...   \n",
       "14048  7f370edef8ae471bb1e3067f84f5a9d0  offer viewed   \n",
       "14049  a9c89c0882154db68a99adcf81eac27e  offer viewed   \n",
       "14050  798d915dfb6a4477adf06802ba29477e  offer viewed   \n",
       "14051  e4c38c75c12f4bec9fb35546b14c5fd5  offer viewed   \n",
       "14052  31bf20236dda4f92b15153c439352a25  offer viewed   \n",
       "\n",
       "                                                  value  time  \n",
       "12650  {'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}     0  \n",
       "12651  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}     0  \n",
       "12652  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0  \n",
       "12653  {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}     0  \n",
       "12655  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}     0  \n",
       "...                                                 ...   ...  \n",
       "14048  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0  \n",
       "14049  {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}     0  \n",
       "14050  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}     0  \n",
       "14051  {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}     0  \n",
       "14052  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}     0  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filer out all the customers who have viewed the offer.\n",
    "viewed_offers_df = df[df['event'] == 'offer viewed'].iloc[0:1000].copy()\n",
    "viewed_offers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method will find out all the cutomers whoi have completed the offers.\n",
    "def is_offer_used(person_id, offer_id, completed_offers):\n",
    "    offer_used = completed_offers[(completed_offers['person'] == person_id) & (completed_offers['offer_id'] == offer_id)]\n",
    "    return int(not offer_used.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>event</th>\n",
       "      <th>value</th>\n",
       "      <th>time</th>\n",
       "      <th>offer_used_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>389bc3fa690240e798340f5a15918d5c</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>d1ede868e29245ea91818a903fec04c6</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>102e9454054946fda62242d2e176fdce</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>02c083884c7d45b39cc68e1314fec56c</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>be8a5d1981a2458d90b255ddc7e0d174</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>7f370edef8ae471bb1e3067f84f5a9d0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>a9c89c0882154db68a99adcf81eac27e</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>798d915dfb6a4477adf06802ba29477e</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>e4c38c75c12f4bec9fb35546b14c5fd5</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>31bf20236dda4f92b15153c439352a25</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 person         event  \\\n",
       "12650  389bc3fa690240e798340f5a15918d5c  offer viewed   \n",
       "12651  d1ede868e29245ea91818a903fec04c6  offer viewed   \n",
       "12652  102e9454054946fda62242d2e176fdce  offer viewed   \n",
       "12653  02c083884c7d45b39cc68e1314fec56c  offer viewed   \n",
       "12655  be8a5d1981a2458d90b255ddc7e0d174  offer viewed   \n",
       "...                                 ...           ...   \n",
       "14048  7f370edef8ae471bb1e3067f84f5a9d0  offer viewed   \n",
       "14049  a9c89c0882154db68a99adcf81eac27e  offer viewed   \n",
       "14050  798d915dfb6a4477adf06802ba29477e  offer viewed   \n",
       "14051  e4c38c75c12f4bec9fb35546b14c5fd5  offer viewed   \n",
       "14052  31bf20236dda4f92b15153c439352a25  offer viewed   \n",
       "\n",
       "                                                  value  time  \\\n",
       "12650  {'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}     0   \n",
       "12651  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}     0   \n",
       "12652  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0   \n",
       "12653  {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}     0   \n",
       "12655  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}     0   \n",
       "...                                                 ...   ...   \n",
       "14048  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}     0   \n",
       "14049  {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}     0   \n",
       "14050  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}     0   \n",
       "14051  {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}     0   \n",
       "14052  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}     0   \n",
       "\n",
       "       offer_used_label  \n",
       "12650                 1  \n",
       "12651                 0  \n",
       "12652                 1  \n",
       "12653                 0  \n",
       "12655                 0  \n",
       "...                 ...  \n",
       "14048                 0  \n",
       "14049                 0  \n",
       "14050                 1  \n",
       "14051                 1  \n",
       "14052                 0  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label 1 if a customer view the offer and also completed the offer.\n",
    "# Label 0 if a customer view the offer but did not complete the offer.\n",
    "viewed_offers_df['offer_used_label'] = viewed_offers_df.apply(lambda row: is_offer_used(row['person'], row['value']['offer id'], completed_offers), axis=1)\n",
    "viewed_offers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person              502\n",
       "event               502\n",
       "value               502\n",
       "time                502\n",
       "offer_used_label    502\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total offers viewed but not completed\n",
    "viewed_offers_df[viewed_offers_df['offer_used_label'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person              498\n",
       "event               498\n",
       "value               498\n",
       "time                498\n",
       "offer_used_label    498\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total offers viewed and completed\n",
    "viewed_offers_df[viewed_offers_df['offer_used_label'] == 1].count()\n",
    "\n",
    "# From above 2 cells we find that data set is balanced as \n",
    "# count for label 0 = 28269\n",
    "# count for label 1 = 29456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>event</th>\n",
       "      <th>person</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>offer_used_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>65</td>\n",
       "      <td>20180209</td>\n",
       "      <td>M</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>389bc3fa690240e798340f5a15918d5c</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>53</td>\n",
       "      <td>20170916</td>\n",
       "      <td>O</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>d1ede868e29245ea91818a903fec04c6</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>69</td>\n",
       "      <td>20160814</td>\n",
       "      <td>F</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>102e9454054946fda62242d2e176fdce</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>20</td>\n",
       "      <td>20160711</td>\n",
       "      <td>F</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>02c083884c7d45b39cc68e1314fec56c</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>39</td>\n",
       "      <td>20140527</td>\n",
       "      <td>M</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>be8a5d1981a2458d90b255ddc7e0d174</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '5a8bc65990b245e5a138643cd4eb9837'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>53</td>\n",
       "      <td>20141201</td>\n",
       "      <td>M</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>7f370edef8ae471bb1e3067f84f5a9d0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>118</td>\n",
       "      <td>20180501</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>a9c89c0882154db68a99adcf81eac27e</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>78</td>\n",
       "      <td>20131229</td>\n",
       "      <td>M</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>798d915dfb6a4477adf06802ba29477e</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>64</td>\n",
       "      <td>20170703</td>\n",
       "      <td>M</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>e4c38c75c12f4bec9fb35546b14c5fd5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>118</td>\n",
       "      <td>20180409</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offer viewed</td>\n",
       "      <td>31bf20236dda4f92b15153c439352a25</td>\n",
       "      <td>0</td>\n",
       "      <td>{'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age became_member_on gender    income         event  \\\n",
       "12650   65         20180209      M   53000.0  offer viewed   \n",
       "12651   53         20170916      O   52000.0  offer viewed   \n",
       "12652   69         20160814      F   57000.0  offer viewed   \n",
       "12653   20         20160711      F   30000.0  offer viewed   \n",
       "12655   39         20140527      M   51000.0  offer viewed   \n",
       "...    ...              ...    ...       ...           ...   \n",
       "14048   53         20141201      M  100000.0  offer viewed   \n",
       "14049  118         20180501   None       NaN  offer viewed   \n",
       "14050   78         20131229      M   57000.0  offer viewed   \n",
       "14051   64         20170703      M   98000.0  offer viewed   \n",
       "14052  118         20180409   None       NaN  offer viewed   \n",
       "\n",
       "                                 person time  \\\n",
       "12650  389bc3fa690240e798340f5a15918d5c    0   \n",
       "12651  d1ede868e29245ea91818a903fec04c6    0   \n",
       "12652  102e9454054946fda62242d2e176fdce    0   \n",
       "12653  02c083884c7d45b39cc68e1314fec56c    0   \n",
       "12655  be8a5d1981a2458d90b255ddc7e0d174    0   \n",
       "...                                 ...  ...   \n",
       "14048  7f370edef8ae471bb1e3067f84f5a9d0    0   \n",
       "14049  a9c89c0882154db68a99adcf81eac27e    0   \n",
       "14050  798d915dfb6a4477adf06802ba29477e    0   \n",
       "14051  e4c38c75c12f4bec9fb35546b14c5fd5    0   \n",
       "14052  31bf20236dda4f92b15153c439352a25    0   \n",
       "\n",
       "                                                  value offer_used_label  \n",
       "12650  {'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}                1  \n",
       "12651  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}                0  \n",
       "12652  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}                1  \n",
       "12653  {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}                0  \n",
       "12655  {'offer id': '5a8bc65990b245e5a138643cd4eb9837'}                0  \n",
       "...                                                 ...              ...  \n",
       "14048  {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}                0  \n",
       "14049  {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}                0  \n",
       "14050  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}                1  \n",
       "14051  {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}                1  \n",
       "14052  {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}                0  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create valid offers and enrich with extra info.\n",
    "valid_offers_df = pd.DataFrame(columns=['age', 'became_member_on', 'gender', 'income', 'event', 'person', 'time', 'value', 'offer_used_label'])\n",
    "for idx, viewed_offer in viewed_offers_df.iterrows():\n",
    "    valid_offers_df.loc[idx] = profile_id_as_index.loc[viewed_offer['person']].append(viewed_offer)\n",
    "valid_offers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 1000\n",
       "became_member_on    1000\n",
       "gender               840\n",
       "income              1000\n",
       "event               1000\n",
       "person              1000\n",
       "time                1000\n",
       "value               1000\n",
       "offer_used_label    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill 0 for income where its not available\n",
    "valid_offers_df['income'].fillna(0, inplace=True)\n",
    "valid_offers_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily drop non-converted features\n",
    "valid_offers_df.drop(['became_member_on', 'gender', 'event', 'person', 'value'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>offer_used_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>65</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>53</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>69</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>20</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>39</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>53</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>78</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>64</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    income time offer_used_label\n",
       "12650   65   53000.0    0                1\n",
       "12651   53   52000.0    0                0\n",
       "12652   69   57000.0    0                1\n",
       "12653   20   30000.0    0                0\n",
       "12655   39   51000.0    0                0\n",
       "...    ...       ...  ...              ...\n",
       "14048   53  100000.0    0                0\n",
       "14049  118       0.0    0                0\n",
       "14050   78   57000.0    0                1\n",
       "14051   64   98000.0    0                1\n",
       "14052  118       0.0    0                0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_offers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into labels and features\n",
    "#valid_offers_used = valid_offers_df['offer_used_label'].copy()\n",
    "valid_offers_used_label = valid_offers_df['offer_used_label'].copy()\n",
    "valid_offers_used_features = valid_offers_df.drop(['offer_used_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(valid_offers_used_features, \n",
    "                                                    valid_offers_used_label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14044    0\n",
       "13843    1\n",
       "13051    0\n",
       "13391    1\n",
       "13567    0\n",
       "Name: offer_used_label, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()\n",
    "y_train.head()\n",
    "\n",
    "X_test.head()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-north-1-186768347586'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data to s3\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # combine labels and features \n",
    "    pd.concat([y, x], axis=1)\\\n",
    "        .to_csv(os.path.join(data_dir, filename), header=False, index=False)\n",
    "    \n",
    "    # indicate function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: data_starbucks/train.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data_starbucks' # the folder I will use for storing data in notebook\n",
    "name = 'train.csv'\n",
    "\n",
    "# create 'train.csv'\n",
    "make_csv(X_train, y_train, name, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-north-1-186768347586/starbucks-capstone/offer-data\n"
     ]
    }
   ],
   "source": [
    "# directory for features data\n",
    "data_dir = 'data_starbucks'\n",
    "\n",
    "# prefix: description name for directory in S3\n",
    "prefix = 'starbucks-capstone/offer-data'\n",
    "\n",
    "# upload all data to S3\n",
    "uploaded_data_s3 = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(uploaded_data_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-scikit-learn-2021-04-11-08-22-07-540/profiler-output/system/incremental/2021041108/1618129440.algo-1.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-22-07-540/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/profiler-output/system/incremental/2021041108/1618130220.algo-1.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/profiler-output/system/incremental/2021041108/1618130280.algo-1.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-report.html\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-report.ipynb\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/BatchSize.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/Dataloader.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/IOBottleneck.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/LoadBalancing.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/rule-output/ProfilerReport-1618130146/profiler-output/profiler-reports/StepOutlier.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-35-46-311/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2021-04-11-08-44-40-362/profiler-output/system/incremental/2021041108/1618130760.algo-1.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-44-40-362/profiler-output/system/incremental/2021041108/1618130820.algo-1.json\n",
      "sagemaker-scikit-learn-2021-04-11-08-44-40-362/source/sourcedir.tar.gz\n",
      "starbucks-capstone/offer-data/train.csv\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SKLearn: LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. \u001b[39;49;00m\r\n",
      "\u001b[37m# from sklearn.externals import joblib\u001b[39;49;00m\r\n",
      "\u001b[37m# Import joblib package directly\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m## TODO: Import any additional libraries you need to define a model\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearSVC\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Provided model load function\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load model from the model_dir. This is the same model that is saved\u001b[39;49;00m\r\n",
      "\u001b[33m    in the main if statement.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# load using joblib\u001b[39;49;00m\r\n",
      "    model = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m## TODO: Complete the main code\u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\r\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\r\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    \r\n",
      "    \u001b[37m## TODO: Add any additional arguments that you will need to pass into your model\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    \u001b[37m# Read in csv training file\u001b[39;49;00m\r\n",
      "    training_dir = args.data_dir\r\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Labels are in the first column\u001b[39;49;00m\r\n",
      "    train_y = train_data.iloc[:,\u001b[34m0\u001b[39;49;00m]\r\n",
      "    train_x = train_data.iloc[:,\u001b[34m1\u001b[39;49;00m:]\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m## --- Your code here --- ##\u001b[39;49;00m\r\n",
      "    \r\n",
      "\r\n",
      "    \u001b[37m## TODO: Define a model \u001b[39;49;00m\r\n",
      "    model = LinearSVC()\r\n",
      "    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m## TODO: Train the model\u001b[39;49;00m\r\n",
      "    model.fit(train_x, train_y)\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m## --- End of your code  --- ##\u001b[39;49;00m\r\n",
      "    \r\n",
      "\r\n",
      "    \u001b[37m# Save the trained model\u001b[39;49;00m\r\n",
      "    joblib.dump(model, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_sklearn/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Define and train model\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                    source_dir='/home/ec2-user/SageMaker/Capstone-Starbucks-Project/source_sklearn',\n",
    "                    role=role,\n",
    "                    py_version=\"py3\",\n",
    "                    framework_version='0.23-1',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.68 µs\n",
      "2021-04-11 08:50:00 Starting - Starting the training job...\n",
      "2021-04-11 08:50:27 Starting - Launching requested ML instancesProfilerReport-1618130999: InProgress\n",
      "......\n",
      "2021-04-11 08:51:28 Starting - Preparing the instances for training......\n",
      "2021-04-11 08:52:28 Downloading - Downloading input data...\n",
      "2021-04-11 08:52:59 Training - Training image download completed. Training in progress..\u001b[34m2021-04-11 08:53:00,253 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:00,261 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:00,276 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:00,596 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:03,620 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:03,634 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:03,651 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-04-11-08-49-59-745\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-north-1-186768347586/sagemaker-scikit-learn-2021-04-11-08-49-59-745/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-north-1-186768347586/sagemaker-scikit-learn-2021-04-11-08-49-59-745/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-04-11-08-49-59-745\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-north-1-186768347586/sagemaker-scikit-learn-2021-04-11-08-49-59-745/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\u001b[0m\n",
      "\u001b[34m2021-04-11 08:53:05,147 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-04-11 08:53:28 Uploading - Uploading generated training model\n",
      "2021-04-11 08:53:28 Completed - Training job completed\n",
      "Training seconds: 56\n",
      "Billable seconds: 56\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Train estimator on S3 training data\n",
    "estimator.fit({'train': uploaded_data_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 205 ms, sys: 15.9 ms, total: 221 ms\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# deploy model to create a predictor\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine accuracy of model\n",
    "# First: generate predicted, class labels\n",
    "test_y_preds = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# test that model generates the correct number of labels\n",
    "assert len(test_y_preds)==len(y_test), 'Unexpected number of predictions.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = pd.DataFrame(y_test).iloc[:,0]\n",
    "converted_test_y = test_y.reset_index(drop=True).values.astype(int)\n",
    "converted_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Second: calculate the test accuracy\n",
    "accuracy = accuracy_score(converted_test_y, test_y_preds.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635\n",
      "\n",
      "Predicted class labels: \n",
      "[0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1\n",
      " 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      "True class labels: \n",
      "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy)\n",
    "\n",
    "## print out the array of predicted and true labels, if you want\n",
    "print('\\nPredicted class labels: ')\n",
    "print(test_y_preds)\n",
    "print('\\nTrue class labels: ')\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch: Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BinaryClassifier\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Load the parameters used to create the model\u001b[39;49;00m\r\n",
      "    model_info = {}\r\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = torch.load(f)\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\r\n",
      "\r\n",
      "    \u001b[37m# Determine the device and construct the model\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model = BinaryClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Load the stored model parameters\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.load_state_dict(torch.load(f))\r\n",
      "\r\n",
      "    \u001b[37m# Set to eval mode, could use no_grad\u001b[39;49;00m\r\n",
      "    model.to(device).eval()\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[37m# Gets training data in batches from the train.csv file\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir):\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Labels are in the first column\u001b[39;49;00m\r\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\r\n",
      "    \u001b[37m# Features are in the remaining columns\u001b[39;49;00m\r\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\r\n",
      "\r\n",
      "    \u001b[37m# Create the dataset\u001b[39;49;00m\r\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Provided training function\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, criterion, optimizer, device):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\r\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\r\n",
      "\u001b[33m    model        - The PyTorch model to be trained.\u001b[39;49;00m\r\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader used during training.\u001b[39;49;00m\r\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\r\n",
      "\u001b[33m    criterion    - The loss function used for training. \u001b[39;49;00m\r\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\r\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Training loop\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\r\n",
      "        model.train() \u001b[37m# Make sure that the model is in training mode.\u001b[39;49;00m\r\n",
      "\r\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\r\n",
      "\r\n",
      "        \u001b[34mfor\u001b[39;49;00m batch \u001b[35min\u001b[39;49;00m train_loader:\r\n",
      "            \u001b[37m# Get data\u001b[39;49;00m\r\n",
      "            batch_x, batch_y = batch\r\n",
      "\r\n",
      "            batch_x = batch_x.to(device)\r\n",
      "            batch_y = batch_y.to(device)\r\n",
      "\r\n",
      "            optimizer.zero_grad()\r\n",
      "\r\n",
      "            \u001b[37m# Get predictions from model\u001b[39;49;00m\r\n",
      "            y_pred = model(batch_x)\r\n",
      "            \r\n",
      "            \u001b[37m# Perform backprop\u001b[39;49;00m\r\n",
      "            loss = criterion(y_pred, batch_y)\r\n",
      "            loss.backward()\r\n",
      "            optimizer.step()\r\n",
      "            \r\n",
      "            total_loss += loss.data.item()\r\n",
      "\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, Loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[37m# All of the model paramaters and training parameters are sent as arguments\u001b[39;49;00m\r\n",
      "    \u001b[37m# when this script is executed during a training job.\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Set up argument parser to access parameters\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data/saving models; automatically set\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    \r\n",
      "    \u001b[37m# Training Parameters\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Model Parameters\u001b[39;49;00m\r\n",
      "    \u001b[37m# Args for model parameters: input_features, hidden_dim, output_dim\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of input features to model (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhidden dim of model (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mOUT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33moutput dim of model (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUsing device \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\r\n",
      "\r\n",
      "    \u001b[37m# Set seed for generating random numbers\u001b[39;49;00m\r\n",
      "    torch.manual_seed(args.seed)\r\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\r\n",
      "        torch.cuda.manual_seed(args.seed)\r\n",
      "\r\n",
      "    \u001b[37m# Load the training data\u001b[39;49;00m\r\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\r\n",
      "\r\n",
      "    \u001b[37m# Build the model with input params.\u001b[39;49;00m\r\n",
      "    \u001b[37m# Model moved to designated device (gpu/cpu).\u001b[39;49;00m\r\n",
      "    model = BinaryClassifier(args.input_features, args.hidden_dim, args.output_dim).to(device)\r\n",
      "\r\n",
      "    \u001b[37m# Define an optimizer and loss function for training\u001b[39;49;00m\r\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\r\n",
      "    criterion = nn.BCELoss()\r\n",
      "\r\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\r\n",
      "    train(model, train_loader, args.epochs, criterion, optimizer, device)\r\n",
      "\r\n",
      "    \u001b[37m# Save model params\u001b[39;49;00m\r\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = {\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.input_features,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.hidden_dim,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.output_dim,\r\n",
      "        }\r\n",
      "        torch.save(model_info, f)\r\n",
      "\r\n",
      "\t\u001b[37m# Save the model \u001b[39;49;00m\r\n",
      "    model_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        torch.save(model.cpu().state_dict(), f)\r\n"
     ]
    }
   ],
   "source": [
    "#PyTorch: Feed Forward Neural Network \n",
    "!pygmentize source_pytorch/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorch Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source_pytorch',\n",
    "                    role=role,\n",
    "                    py_version=\"py3\",\n",
    "                    framework_version='1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m5.large',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'input_features': 3, # number of features\n",
    "                        'hidden_dim': 2,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 80\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 09:15:35 Starting - Starting the training job...\n",
      "2021-04-11 09:15:37 Starting - Launching requested ML instancesProfilerReport-1618132534: InProgress\n",
      "......\n",
      "2021-04-11 09:16:43 Starting - Preparing the instances for training......\n",
      "2021-04-11 09:18:05 Downloading - Downloading input data\n",
      "2021-04-11 09:18:05 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:06,410 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:06,413 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:06,429 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:07,058 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:07,296 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:07,296 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:07,296 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:07,296 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dok02gj2/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 21.0.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:09,051 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:09,063 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 2,\n",
      "        \"input_features\": 3,\n",
      "        \"epochs\": 80,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2021-04-11-09-15-34-989\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-north-1-186768347586/sagemaker-pytorch-2021-04-11-09-15-34-989/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":80,\"hidden_dim\":2,\"input_features\":3,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-north-1-186768347586/sagemaker-pytorch-2021-04-11-09-15-34-989/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":80,\"hidden_dim\":2,\"input_features\":3,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2021-04-11-09-15-34-989\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-north-1-186768347586/sagemaker-pytorch-2021-04-11-09-15-34-989/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"80\",\"--hidden_dim\",\"2\",\"--input_features\",\"3\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=2\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=3\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=80\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 80 --hidden_dim 2 --input_features 3 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.7409974582493305\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.7210735954344273\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.6863133743405342\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.6825820952653885\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.6672697767615319\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.6626736655831337\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.6578768469393254\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.6571781419217586\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.6630887217819691\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.663642343878746\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.6562722533941269\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.6552920408546925\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.6602026961743832\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.6548587299883366\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.6526322294026613\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.6585125222802162\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.6581652455031872\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.6600281275808811\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.6605540797114372\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.6565803244709969\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.6559301070868969\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.6607657343149185\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.6538636088371277\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.6609018549323082\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.6557842060923577\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.6649760738015175\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.6646411582827568\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.6604719415307045\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.658128672093153\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.6621547237038612\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.6623470146209002\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.6580827455967665\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.6621331542730331\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.656681702286005\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.6580805856734514\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.6578128606081008\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.6586968101561069\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.658199093490839\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.6654771886765957\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.658401657640934\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.659476874768734\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.6568270973861218\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.6588307447731495\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.6620755180716514\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.6643134258687496\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.6539838775992394\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.6615077160298825\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.6602334313094615\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.6603220276534557\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.6601611256599427\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.6566050373017788\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.6529056958854198\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.6596822954714299\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.6615379109978676\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.6598561100661755\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.6620803013443947\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.6577839002013206\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.6512479245662689\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.6661778330802918\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.6660881742835045\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.6617325432598591\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.6571382768452168\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.6612297482788563\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.6605166010558605\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.6640573583543301\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.6620374597609043\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.6598999537527561\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.6653980374336242\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.6613503254950046\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.6579188495874405\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.6592492431402206\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.6594824880361557\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.6553712986409664\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.6504708014428615\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.6645108252763748\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.6644274234771729\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.6627187430858612\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.6638977319002152\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.6590852998197079\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.6600277327001095\u001b[0m\n",
      "\u001b[34m2021-04-11 09:18:14,316 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-04-11 09:18:32 Uploading - Uploading generated training model\n",
      "2021-04-11 09:18:32 Completed - Training job completed\n",
      "Training seconds: 42\n",
      "Billable seconds: 42\n",
      "CPU times: user 531 ms, sys: 44 ms, total: 575 ms\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': uploaded_data_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role=role,\n",
    "                     py_version=\"py3\",\n",
    "                     framework_version='1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='source_pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!CPU times: user 212 ms, sys: 10.7 ms, total: 223 ms\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data\n",
    "X_test_converted = X_test.reset_index(drop=True).values.astype(int)\n",
    "y_test_converted = test_y.reset_index(drop=True).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # rounding and squeezing array\n",
    "    test_preds = np.squeeze(np.round(predictor.predict(test_features)))\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions  0.0  1.0\n",
      "actuals              \n",
      "0             33   71\n",
      "1              4   92\n",
      "\n",
      "Recall:     0.958\n",
      "Precision:  0.564\n",
      "Accuracy:   0.625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get metrics for custom predictor\n",
    "metrics = evaluate(predictor, X_test_converted, y_test_converted, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
